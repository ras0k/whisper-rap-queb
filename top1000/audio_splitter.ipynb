{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title Install Dependencies & Run Bulk Tool\n",
        "!pip install -q gradio pydub openai-whisper rapidfuzz\n",
        "!apt-get install -y ffmpeg\n",
        "\n",
        "import gradio as gr\n",
        "from pydub import AudioSegment\n",
        "import whisper\n",
        "import os\n",
        "import shutil\n",
        "import string\n",
        "from rapidfuzz import fuzz\n",
        "from pathlib import Path\n",
        "\n",
        "# Load Whisper model\n",
        "print(\"Loading Whisper model...\")\n",
        "model = whisper.load_model(\"medium\")\n",
        "print(\"Model loaded.\")\n",
        "\n",
        "def get_chunk_letter(index):\n",
        "    \"\"\"Converts 0 -> A, 1 -> B, ..., 26 -> AA...\"\"\"\n",
        "    letters = \"\"\n",
        "    while index >= 0:\n",
        "        letters = chr(index % 26 + 65) + letters\n",
        "        index = index // 26 - 1\n",
        "    return letters\n",
        "\n",
        "def find_best_split_point(whisper_text, source_text_window):\n",
        "    \"\"\"\n",
        "    Finds the best cut-off point in the source text that matches the whisper text.\n",
        "    \"\"\"\n",
        "    if not whisper_text or len(whisper_text.strip()) == 0:\n",
        "        return 0\n",
        "\n",
        "    target_len = len(whisper_text)\n",
        "    best_ratio = 0\n",
        "    best_length = 0\n",
        "\n",
        "    # Heuristic window: 70% to 150% of whisper length\n",
        "    min_search = int(target_len * 0.7)\n",
        "    max_search = int(target_len * 1.5)\n",
        "    max_search = min(max_search, len(source_text_window))\n",
        "\n",
        "    if max_search <= min_search:\n",
        "        return max_search\n",
        "\n",
        "    # Scan for best match\n",
        "    for length in range(min_search, max_search, 5):\n",
        "        candidate = source_text_window[:length]\n",
        "        score = fuzz.ratio(whisper_text, candidate)\n",
        "\n",
        "        if score >= best_ratio:\n",
        "            best_ratio = score\n",
        "            best_length = length\n",
        "\n",
        "    # Snap to nearest space to avoid cutting words\n",
        "    ref_end = best_length\n",
        "    for i in range(0, 15): # Look 15 chars left/right for a space\n",
        "        if ref_end + i < len(source_text_window) and source_text_window[ref_end + i] == ' ':\n",
        "            return ref_end + i\n",
        "        if ref_end - i > 0 and source_text_window[ref_end - i] == ' ':\n",
        "            return ref_end - i\n",
        "\n",
        "    return best_length\n",
        "\n",
        "def process_single_pair(audio_path, text_path, master_output_dir):\n",
        "    \"\"\"\n",
        "    Processes a single Audio/Text pair and writes to master_output_dir\n",
        "    \"\"\"\n",
        "    base_name = Path(audio_path).stem\n",
        "\n",
        "    # Create a subfolder for this song inside the master output\n",
        "    song_dir = os.path.join(master_output_dir, base_name)\n",
        "    os.makedirs(song_dir, exist_ok=True)\n",
        "\n",
        "    logs = [f\"=== Processing: {base_name} ===\"]\n",
        "\n",
        "    # Load Audio\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(audio_path)\n",
        "    except Exception as e:\n",
        "        return [f\"Error loading audio {base_name}: {str(e)}\"]\n",
        "\n",
        "    # Load Text\n",
        "    try:\n",
        "        with open(text_path, 'r', encoding='utf-8') as f:\n",
        "            full_lyrics = f.read().replace('\\r', '').replace('\\n', ' ').strip()\n",
        "            while \"  \" in full_lyrics:\n",
        "                full_lyrics = full_lyrics.replace(\"  \", \" \")\n",
        "    except Exception as e:\n",
        "        return [f\"Error loading text {base_name}: {str(e)}\"]\n",
        "\n",
        "    # Calculate Chunks\n",
        "    chunk_length_ms = 30 * 1000\n",
        "    total_length_ms = len(audio)\n",
        "    num_chunks = total_length_ms // chunk_length_ms\n",
        "\n",
        "    current_text_idx = 0\n",
        "\n",
        "    for i in range(num_chunks):\n",
        "        start_ms = i * chunk_length_ms\n",
        "        end_ms = (i + 1) * chunk_length_ms\n",
        "\n",
        "        chunk = audio[start_ms:end_ms]\n",
        "\n",
        "        # Naming\n",
        "        chunk_letter = get_chunk_letter(i)\n",
        "        mp3_name = f\"{base_name}-{chunk_letter}.mp3\"\n",
        "        txt_name = f\"{base_name}-{chunk_letter}.txt\"\n",
        "\n",
        "        mp3_out = os.path.join(song_dir, mp3_name)\n",
        "        txt_out = os.path.join(song_dir, txt_name)\n",
        "\n",
        "        # Export Audio\n",
        "        chunk.export(mp3_out, format=\"mp3\")\n",
        "\n",
        "        # Transcribe\n",
        "        result = model.transcribe(mp3_out)\n",
        "        whisper_text = result[\"text\"].strip()\n",
        "\n",
        "        # Align\n",
        "        remaining_text = full_lyrics[current_text_idx:]\n",
        "        match_len = find_best_split_point(whisper_text, remaining_text)\n",
        "\n",
        "        real_lyrics_segment = remaining_text[:match_len].strip()\n",
        "\n",
        "        # Export Text\n",
        "        with open(txt_out, \"w\", encoding=\"utf-8\") as tf:\n",
        "            tf.write(real_lyrics_segment)\n",
        "\n",
        "        current_text_idx += match_len\n",
        "\n",
        "        logs.append(f\"  [{chunk_letter}] Matches: {real_lyrics_segment[:30]}...\")\n",
        "\n",
        "    return logs\n",
        "\n",
        "def bulk_process(audio_files, text_files):\n",
        "    # Setup Master Directory\n",
        "    master_dir = \"batch_output\"\n",
        "    if os.path.exists(master_dir):\n",
        "        shutil.rmtree(master_dir)\n",
        "    os.makedirs(master_dir)\n",
        "\n",
        "    global_logs = []\n",
        "\n",
        "    # Sort files to help potential matching, though we use dicts below\n",
        "    if not audio_files or not text_files:\n",
        "        return None, \"Error: Please upload both Audio and Text files.\"\n",
        "\n",
        "    # Map filenames (without extension) to file paths\n",
        "    audio_map = {Path(f).stem: f for f in audio_files}\n",
        "    text_map = {Path(f).stem: f for f in text_files}\n",
        "\n",
        "    # Find matches\n",
        "    matches = []\n",
        "    for name, audio_path in audio_map.items():\n",
        "        if name in text_map:\n",
        "            matches.append((audio_path, text_map[name]))\n",
        "        else:\n",
        "            global_logs.append(f\"⚠️ WARNING: No matching text file found for audio: {name}\")\n",
        "\n",
        "    for name in text_map:\n",
        "        if name not in audio_map:\n",
        "            global_logs.append(f\"⚠️ WARNING: No matching audio file found for text: {name}\")\n",
        "\n",
        "    global_logs.append(f\"Found {len(matches)} valid pairs to process.\\n\")\n",
        "\n",
        "    # Process Loop\n",
        "    for audio_path, text_path in matches:\n",
        "        song_logs = process_single_pair(audio_path, text_path, master_dir)\n",
        "        global_logs.extend(song_logs)\n",
        "        global_logs.append(\"\") # Spacer\n",
        "\n",
        "    # Zip everything\n",
        "    shutil.make_archive(\"batch_processed\", 'zip', master_dir)\n",
        "\n",
        "    return \"batch_processed.zip\", \"\\n\".join(global_logs)\n",
        "\n",
        "# Gradio Interface\n",
        "iface = gr.Interface(\n",
        "    fn=bulk_process,\n",
        "    inputs=[\n",
        "        gr.File(file_count=\"multiple\", label=\"Upload MP3 Files\"),\n",
        "        gr.File(file_count=\"multiple\", label=\"Upload TXT Files\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.File(label=\"Download Master Zip\"),\n",
        "        gr.Textbox(label=\"Processing Log\", lines=20)\n",
        "    ],\n",
        "    title=\"Bulk MP3 Splitter & Lyric Aligner\",\n",
        "    description=\"Upload multiple MP3s and multiple TXTs. Files with the same name will be paired and processed.\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "id": "-ms50yG7_x_H",
        "outputId": "b8914db5-8665-49d1-c49a-cb0901dba02f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/803.2 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Loading Whisper model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:19<00:00, 77.7MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://29ddbe687af2e5199e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://29ddbe687af2e5199e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}